{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e542a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize  import word_tokenize, sent_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"omw-1.4\")\n",
    "from ast import literal_eval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "266cfb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv(r\"C:\\Users\\dell\\Desktop\\dataset\\Hotel_Reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9368e6c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(515738, 17)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9784566d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for simplicty will change the countroes name to Alpgha-2 codes\n",
    "data.Hotel_Address = data.Hotel_Address.str.replace(\"Netherlands\", \"NL\")\n",
    "data.Hotel_Address = data.Hotel_Address.str.replace(\"United Kingdom\", \"UK\")\n",
    "data.Hotel_Address = data.Hotel_Address.str.replace(\"France\", \"FR\")\n",
    "data.Hotel_Address = data.Hotel_Address.str.replace(\"Italy\", \"IT\")\n",
    "data.Hotel_Address = data.Hotel_Address.str.replace(\"Spain\", \"SP\")\n",
    "data.Hotel_Address = data.Hotel_Address.str.replace(\"Austria\", \"AT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06bd7d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  will add or deriv a new cloumn from last string at ho0tel address wich specify where the hotel loctated \n",
    "# data[\"countries\"] =[ x[-2:] for x in data.Hotel_Address]\n",
    "data[\"countries\"] = data.Hotel_Address.apply(lambda x: x.split(' ')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e6d7071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NL', 'UK', 'FR', 'SP', 'IT', 'AT'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to make sure that Counties added will use unique() to retrieve unique words at the column  \n",
    "data.countries.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d8e75f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Hotel_Address', 'Average_Score', 'Hotel_Name', 'Tags', 'countries'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# will show all columns to drop needn't data \n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8f87610",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Additional_Number_of_Scoring', 'Review_Date', 'Reviewer_Nationality', 'Negative_Review', 'Review_Total_Negative_Word_Counts', 'Total_Number_of_Reviews', 'Positive_Review', 'Review_Total_Positive_Word_Counts', 'Total_Number_of_Reviews_Reviewer_Has_Given', 'Reviewer_Score', 'days_since_review', 'lat', 'lng'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1560\\3340045073.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# will work in new dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m data.drop(['Additional_Number_of_Scoring', 'Review_Date',\n\u001b[0m\u001b[0;32m      3\u001b[0m        \u001b[1;34m'Reviewer_Nationality'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m        \u001b[1;34m'Negative_Review'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Review_Total_Negative_Word_Counts'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m        \u001b[1;34m'Total_Number_of_Reviews'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Positive_Review'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4955\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[1;36m1.0\u001b[0m     \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4956\u001b[0m         \"\"\"\n\u001b[1;32m-> 4957\u001b[1;33m         return super().drop(\n\u001b[0m\u001b[0;32m   4958\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4959\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4265\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4266\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4267\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4269\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors, consolidate, only_slice)\u001b[0m\n\u001b[0;32m   4309\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4310\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4311\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4312\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6659\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6660\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6661\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{list(labels[mask])} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6662\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6663\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Additional_Number_of_Scoring', 'Review_Date', 'Reviewer_Nationality', 'Negative_Review', 'Review_Total_Negative_Word_Counts', 'Total_Number_of_Reviews', 'Positive_Review', 'Review_Total_Positive_Word_Counts', 'Total_Number_of_Reviews_Reviewer_Has_Given', 'Reviewer_Score', 'days_since_review', 'lat', 'lng'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# will work in new dataset\n",
    "data.drop(['Additional_Number_of_Scoring', 'Review_Date',\n",
    "       'Reviewer_Nationality',\n",
    "       'Negative_Review', 'Review_Total_Negative_Word_Counts',\n",
    "       'Total_Number_of_Reviews', 'Positive_Review',\n",
    "       'Review_Total_Positive_Word_Counts',\n",
    "       'Total_Number_of_Reviews_Reviewer_Has_Given', 'Reviewer_Score',\n",
    "       'days_since_review', 'lat', 'lng'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efaf40a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Hotel_Address', 'Average_Score', 'Hotel_Name', 'Tags', 'countries'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9337aa3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1560\\3038928563.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# create a function help us to convert object(pandas.core.series.Series) to List then to Sring from Tags\n",
    "def convert(column):\n",
    "    column = column[0]\n",
    "    if (type(column) != list):\n",
    "        return \"\".join(literal_eval(column))\n",
    "    else:\n",
    "        return column    \n",
    "dataset.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6a6833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# will call the convert function to change object dataType of column Tags to Srting \n",
    "# dataset['Tags'] = dataset[['Tags']].apply(convert, axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e86619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To simplicty => change Countries and Tags columns to lowercase\n",
    "data[\"Tags\"]= data[\"Tags\"].str.lower()\n",
    "data[\"countries\"]= data[\"countries\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdaa42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  model\n",
    "# location => Counties , description => Tags\n",
    "def recomender(location , description):\n",
    "#  lemmatiaztion for Tags column     \n",
    "    description =  description.lower()\n",
    "    word_tokenize(description)\n",
    "    stop_words  =  stopwords.words(\"english\")\n",
    "    lemm  =  WordNetLemmatizer()\n",
    "    \n",
    "#     cheching there is a stopwords, if no will add at list \n",
    "    filtered= {word for word in description if not word in stop_words}\n",
    "    filtered_set = set()\n",
    "    for fs in filtered:\n",
    "        filtered_set.add(lemm.lemmatize(fs))\n",
    "        \n",
    "        \n",
    "#    creating varible refer to all countires == to location i want  \n",
    "    country = data[data['countries']==location.lower()]\n",
    "#     set index by using numpy                   shape[0]=> [0]> num of rows  \n",
    "    country = country.set_index(np.arange(country.shape[0]))\n",
    "    \n",
    "    list1 = []\n",
    "    list2 = [] \n",
    "    cos   = []\n",
    "    \n",
    "#     for loop to iteration of all rows    \n",
    "    for i in range(country.shape[0]):\n",
    "        \n",
    "#     make tokinze and then, filter from stopwords\n",
    "        temp_token = word_tokenize(country[\"Tags\"][i])\n",
    "        temp_set   = [word for word in temp_token if not word in stop_words]\n",
    "#       list grouping the lemmatizetion of words tokenization  \n",
    "        temp2_set =set()\n",
    "        for xx in temp_set:\n",
    "            temp2_set.add(lemm.lemmatize(xx))\n",
    "        vector = temp2_set.intersection(filtered_set)\n",
    "        cos.append(len(vector))\n",
    "    country['similarity'] = cos\n",
    "#     arange hotels by using tags rating \n",
    "    country = country.sort_values(by=\"similarity\", ascending=False)\n",
    "#                                   require            ,optional ^defult\n",
    "    country.drop_duplicates(subset='Hotel_Name', keep=\"first\", inplace= True)\n",
    "    \n",
    "    country.sort_values('Average_Score', ascending=False, inplace=True)\n",
    "    country.reset_index(inplace = True)\n",
    "    return country[[\"Hotel_Name\", \"Average_Score\", \"Hotel_Address\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d216018",
   "metadata": {},
   "outputs": [],
   "source": [
    "recomender('FR','Business trip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad645fad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d5389c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac7f18c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
